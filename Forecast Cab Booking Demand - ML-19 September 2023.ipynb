{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860434a2",
   "metadata": {},
   "source": [
    "### Importing required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75304c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b8306",
   "metadata": {},
   "source": [
    "### Loading train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'D:\\AI\\Education\\PGD in Ai and ML\\dataset\\ml\\train.csv') #my local path\n",
    "\n",
    "test = pd.read_csv(r'D:\\AI\\Education\\PGD in Ai and ML\\dataset\\ml\\test.csv') #my local path\n",
    "\n",
    "print(\"Training Data Sample:\")\n",
    "print(train.head())\n",
    "\n",
    "print(\"\\nTesting Data Sample:\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b668f47",
   "metadata": {},
   "source": [
    "### Getting shape of train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shape = train.shape\n",
    "print(\"Training Data Shape:\", train_shape)\n",
    "\n",
    "test_shape = test.shape\n",
    "print(\"Testing Data Shape:\", test_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf52fd7",
   "metadata": {},
   "source": [
    "### Datatypes of each column in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523eeac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dtype = train.info()\n",
    "print(\"Training Datatypes:\", train_dtype)\n",
    "\n",
    "print(\"=====================================================================================\")\n",
    "\n",
    "test_dtype = test.info()\n",
    "print(\"Testing Datatypes:\", test_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e314b903",
   "metadata": {},
   "source": [
    "### Find missing columns in train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c398aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_missing_values = train.isnull().sum()\n",
    "print(\"Missing Values in Training Data:\")\n",
    "print(train_missing_values)\n",
    "\n",
    "test_missing_values = test.isnull().sum()\n",
    "print(\"\\nMissing Values in Testing Data:\")\n",
    "print(test_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7a1a5",
   "metadata": {},
   "source": [
    "### Creating new columns date, hour, weekDay, month from datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe88a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "\n",
    "train['date'] = train['datetime'].dt.date\n",
    "train['hour'] = train['datetime'].dt.hour\n",
    "train['weekDay'] = train['datetime'].dt.dayofweek\n",
    "train['month'] = train['datetime'].dt.month\n",
    "\n",
    "print(train[['datetime', 'date', 'hour', 'weekDay', 'month']].head())\n",
    "\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "\n",
    "test['date'] = test['datetime'].dt.date\n",
    "test['hour'] = test['datetime'].dt.hour\n",
    "test['weekDay'] = test['datetime'].dt.dayofweek\n",
    "test['month'] = test['datetime'].dt.month\n",
    "\n",
    "print(test[['datetime', 'date', 'hour', 'weekDay', 'month']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f40369",
   "metadata": {},
   "source": [
    "### Coercing the datatype of season, holiday, workingday, and weather to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cccc232",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_columns = ['season', 'holiday', 'workingday', 'weather']\n",
    "\n",
    "train[category_columns] = train[category_columns].astype('category')\n",
    "\n",
    "test[category_columns] = test[category_columns].astype('category')\n",
    "\n",
    "print(\"Data Types in Training Data:\")\n",
    "print(train.dtypes)\n",
    "\n",
    "print(\"\\nUpdated Training Data Head:\")\n",
    "print(train.head())\n",
    "\n",
    "print(\"Data Types in Test Data:\")\n",
    "print(test.dtypes)\n",
    "\n",
    "print(\"\\nUpdated Test Data Head:\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ceeffc",
   "metadata": {},
   "source": [
    "### Droping the 'datetime' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ecc512",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('datetime', axis=1)\n",
    "\n",
    "test = test.drop('datetime', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ca1e4f",
   "metadata": {},
   "source": [
    "### Printing all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.columns)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b4c2e",
   "metadata": {},
   "source": [
    "### Outlier Analysis:  Box plots across various features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5065a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "\n",
    "# Box plot for season\n",
    "sns.boxplot(x='season', y='Total_booking', data=train, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Box Plot of Total Booking vs. Season')\n",
    "\n",
    "# Box plot for hour\n",
    "sns.boxplot(x='hour', y='Total_booking', data=train, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Box Plot of Total Booking vs. Hour of the Day')\n",
    "\n",
    "# Box plot for workingday\n",
    "sns.boxplot(x='workingday', y='Total_booking', data=train, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Box Plot of Total Booking vs. Working Day')\n",
    "\n",
    "# Box plot for weather\n",
    "sns.boxplot(x='weather', y='Total_booking', data=train, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Box Plot of Total Booking vs. Weather')\n",
    "\n",
    "train = train.loc[:,~train.columns.duplicated()]\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0070ff",
   "metadata": {},
   "source": [
    "I observed outliers in the relationship between seasons and total bookings. Specifically, during the fall season, total bookings exceeded 800 tickets, in spring, it exceeded 400, in summer, it surpassed 775, and in winter, it went beyond 680. These outliers suggest varying patterns of cab demand throughout the year.\n",
    "\n",
    "In the analysis of hourly data for cab bookings, several outliers were identified in specific time intervals. Outliers were observed during the hours of 10:00 AM to 3:00 PM, as well as at 11:00 AM and 12:00 PM, and during the early morning hours from 1:00 AM to 3:00 AM. These outliers indicate unusual patterns in cab booking demand during these time slots.\n",
    "\n",
    "Certainly, in the analysis of cab bookings, it was observed that on non-working days, there were outliers with total bookings exceeding 700 bookings, while on working days, outliers occurred when total bookings surpassed 600 tickets.\n",
    "\n",
    "The absence of outliers in holiday-related data, coupled with the presence of outliers in non-holiday data, suggests that there may be distinctive patterns in cab bookings between holidays and regular days. It's possible that during holidays, the demand for cab services remains relatively consistent and doesn't exhibit extreme variations, leading to the absence of outliers. On the other hand, during non-holidays, various factors such as work commutes, events, or other activities may lead to fluctuations in cab demand, resulting in the identification of outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92734ffe",
   "metadata": {},
   "source": [
    "### Outlier Analysis:  Removing the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "columns_to_remove_outliers = ['temp', 'atemp', 'humidity', 'windspeed']\n",
    "\n",
    "for column in columns_to_remove_outliers:\n",
    "    train = remove_outliers_iqr(train, column)\n",
    "\n",
    "print(\"Shape of the Dataset after Removing Outliers:\", train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef9612",
   "metadata": {},
   "source": [
    "### Correlation Analysis:  Plot a correlation plot between \"total booking\" and [\"temp\", \"atemp\", \"humidity\", \"windspeed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"Total_booking\", \"temp\", \"atemp\", \"humidity\", \"windspeed\"]\n",
    "\n",
    "subset_train = train[selected_columns]\n",
    "\n",
    "correlation_matrix = subset_train.corr()\n",
    "\n",
    "# Heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c684b68",
   "metadata": {},
   "source": [
    "## Analysis and Inference from Correlation Heatmap:\n",
    "\n",
    "### Total Booking vs. Temperature (temp and atemp):\n",
    "There is a moderate positive correlation between Total_booking and both temp and atemp (0.39 and 0.39, respectively). This suggests that as the temperature increases, there is a tendency for an increase in cab bookings. The correlation between temp and atemp is very high (0.99), indicating that these two variables are essentially measuring the same thing.\n",
    "\n",
    "### Total Booking vs. Humidity:\n",
    "There is a moderate negative correlation between Total_booking and humidity (-0.32). This implies that as humidity increases, cab bookings tend to decrease. High humidity might deter people from using cab services.\n",
    "\n",
    "### Total Booking vs. Windspeed:\n",
    "There is a weak positive correlation between Total_booking and windspeed (0.09). The correlation is not very strong, suggesting that windspeed has only a slight influence on cab bookings. Other factors likely play a more significant role.\n",
    "\n",
    "## Inference:\n",
    "\n",
    "### Weather Impact:\n",
    "The positive correlation between temperature (temp and atemp) and cab bookings indicates that people are more inclined to book cabs on warmer days. Conversely, the negative correlation with humidity suggests that people are less likely to book cabs on humid days, possibly due to more comfortable outdoor conditions.\n",
    "\n",
    "### Windspeed's Limited Impact:\n",
    "Windspeed shows a weak positive correlation with cab bookings, suggesting that it has a relatively minor impact. Other factors, such as temperature and humidity, likely have a more substantial influence on demand.\n",
    "\n",
    "### Multicollinearity:\n",
    "temp and atemp exhibit a very high correlation, indicating multicollinearity. When building predictive models, it might be beneficial to choose one of these variables to avoid redundancy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b355c6",
   "metadata": {},
   "source": [
    "### Data Visualization: total_booking column and plotting the probability distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4218a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram to visualize the distribution of the total booking column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train[\"Total_booking\"], kde=True, color=\"blue\")\n",
    "plt.title(\"Distribution of Total Booking\")\n",
    "plt.xlabel(\"Total Booking\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Probability distribution plot using kernel density estimate\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.kdeplot(train[\"Total_booking\"], shade=True, color=\"green\")\n",
    "plt.title(\"Probability Distribution of Total Booking\")\n",
    "plt.xlabel(\"Total Booking\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac121d4",
   "metadata": {},
   "source": [
    "### Visualizing total_booking vs (Month, Season, Hour, Weekday, Usertype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63341886",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 10))\n",
    "\n",
    "# Total Booking vs Month\n",
    "sns.barplot(x='month', y='Total_booking', data=train, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Total Booking vs. Month')\n",
    "axes[0, 0].set_xlabel('Month')\n",
    "axes[0, 0].set_ylabel('Total Booking')\n",
    "\n",
    "# Total Booking vs Season\n",
    "sns.barplot(x='season', y='Total_booking', data=train, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Total Booking vs. Season')\n",
    "axes[0, 1].set_xlabel('Season')\n",
    "axes[0, 1].set_ylabel('Total Booking')\n",
    "\n",
    "# Total Booking vs Hour\n",
    "sns.barplot(x='hour', y='Total_booking', data=train, ax=axes[0, 2])\n",
    "axes[0, 2].set_title('Total Booking vs. Hour of the Day')\n",
    "axes[0, 2].set_xlabel('Hour')\n",
    "axes[0, 2].set_ylabel('Total Booking')\n",
    "\n",
    "# Total Booking vs Weekday\n",
    "sns.barplot(x='weekDay', y='Total_booking', data=train, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Total Booking vs. Weekday')\n",
    "axes[1, 0].set_xlabel('Weekday')\n",
    "axes[1, 0].set_ylabel('Total Booking')\n",
    "\n",
    "# Removing the empty subplot\n",
    "fig.delaxes(axes[1, 2])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd879c3",
   "metadata": {},
   "source": [
    "### Using Histograms to plot all the continuous variables in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_variables = [\"temp\", \"atemp\", \"humidity\", \"windspeed\"]\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "\n",
    "for i, var in enumerate(continuous_variables):\n",
    "    row, col = i // 2, i % 2\n",
    "    sns.histplot(train[var], ax=axes[row, col], kde=True, color=\"blue\")\n",
    "    axes[row, col].set_title(f'Histogram of {var}')\n",
    "    axes[row, col].set_xlabel(var)\n",
    "    axes[row, col].set_ylabel('Total_booking')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58040ca2",
   "metadata": {},
   "source": [
    "### Converting the categorical variables into one hot vector using pd.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda83e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['season', 'holiday', 'workingday', 'weather']\n",
    "\n",
    "train = pd.get_dummies(train, columns=categorical_variables, drop_first=True)\n",
    "\n",
    "test = pd.get_dummies(test, columns=categorical_variables, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec44fd7",
   "metadata": {},
   "source": [
    "### Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39363d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'D:\\AI\\Education\\PGD in Ai and ML\\dataset\\ml\\train.csv') # My local path\n",
    "\n",
    "X = train.drop(columns=['Total_booking'])\n",
    "y = train['Total_booking']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c5d6b8",
   "metadata": {},
   "source": [
    "### Fitting Random Forest Regressor, Ada Boost Regressor, Bagging Regressor, SVR, and K-Neighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ed133",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b7dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('date', axis=1)\n",
    "X_test = X_test.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "models = {\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"Ada Boost Regressor\": AdaBoostRegressor(),\n",
    "    \"Bagging Regressor\": BaggingRegressor(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # r2 Score\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"{model_name} MAE: {mae}\")\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{model_name} R2 Score: {r2}\")\n",
    "    \n",
    "    print(\"===========================================================\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f19050c",
   "metadata": {},
   "source": [
    "The Random Forest Regressor outperforms all other models with the lowest MAE of 43.25 and the highest R2 Score of 0.8679. This indicates that the Random Forest model has the smallest prediction errors and explains a significant portion of the variance in the data. It is the top-performing model in terms of both accuracy and fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2952d30",
   "metadata": {},
   "source": [
    "### Displaying a factor plot to visualize the RMSE values achieved by different modeling algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rmse_values = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    rmse_values.append((model_name, rmse))\n",
    "\n",
    "rmse_df = pd.DataFrame(rmse_values, columns=['Model', 'RMSE'])\n",
    "\n",
    "colors = sns.color_palette(\"Set2\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))  \n",
    "sns.lineplot(data=rmse_df, x='Model', y='RMSE', palette=colors)\n",
    "plt.title('RMSE by Modeling Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ccd4b",
   "metadata": {},
   "source": [
    "###  Hyper-parameter tuning on the best model using GridSearchCV and Printing best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Create the gridcv object\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Making predctions using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate rmse using the best model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE using best model:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50782043",
   "metadata": {},
   "source": [
    "###  Prediction on the test set and print the mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8310620",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestRegressor(random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_data.drop(columns=['Total_booking'])  \n",
    "y_test = test_data['Total_booking']  \n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculating the mean squared log error\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Log Error (MSLE):\", msle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
